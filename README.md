# Supplementary material for "A machine-learning approach for the detection of thermostable &beta;-glucosidases"

**Figure S1.** &nbsp;Accuracy values obtained for different hyperparameter definitions of the KNN model. K-values used: 3, 5, 7, 9, 11, 13, and 15.</span></p><p class="c0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 456.98px; height: 246.82px;"><img alt="" src="images/image5.png" style="width: 456.98px; height: 246.82px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p>
**Figure S2.** &nbsp;Accuracy values obtained for different hyperparameter definitions of the Random Forest model. Number of trees used: 3, 5, 10, and 12.</span></p><p class="c0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 464.50px; height: 250.71px;"><img alt="" src="images/image2.png" style="width: 464.50px; height: 250.71px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p>
**Figure S3.** &nbsp;Accuracy values obtained for different hyperparameter definitions of the SVM model. SVM Parameters used: linear, polynomial, rbf, and sigmoid. </span></p><p class="c0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 455.54px; height: 246.04px;"><img alt="" src="images/image8.png" style="width: 455.54px; height: 246.04px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p>
**Figure S4.**  Accuracy values obtained for different hyperparameter definitions of the Neural Network model. Number of neurons in hidden layers used: 50, 100, 150, and 200.</span></p><p class="c0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 449.58px; height: 242.82px;"><img alt="" src="images/image7.png" style="width: 449.58px; height: 242.82px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p>
**Figure S5.**  Accuracy values obtained for different hyperparameter definitions of the catboost model. Number of trees used: 50, 100, and 200.</span></p><p class="c0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 446.08px; height: 240.93px;"><img alt="" src="images/image4.png" style="width: 446.08px; height: 240.93px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p>
**Figure S6.** &nbsp;Accuracy values obtained for different hyperparameter definitions of the Logistic Regression model. Regularization types used: Lasso (R1), Ridge (L2), and None.</span></p><p class="c0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 439.62px; height: 250.04px;"><img alt="" src="images/image6.png" style="width: 439.62px; height: 250.04px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p>
**Figure S7.** &nbsp;Time for training obtained for different hyperparameter definitions of the Logistic Regression model. Regularization types used: Lasso (R1), Ridge (L2), and None.</span></p><p class="c0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 446.27px; height: 253.82px;"><img alt="" src="images/image3.png" style="width: 446.27px; height: 253.82px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p>
**Figure S8.** &nbsp;Time for training the models: Logistic Regression, Gradient Boosting (scikit-learn), Neural Network, catboost (Gradient Boosting), Random Forest, KNN, and SVM.</span></p><p class="c0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 457.23px; height: 246.96px;"><img alt="" src="images/image1.png" style="width: 457.23px; height: 246.96px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p>